#谢雨馨2020145114（第一次作业）
# 预习报告：

## 1、什么是MapReduce

　　Hadoop的MapReduce是一个**软件框架**，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种**可靠的**，具**有容错能力的**方式并行地处理上TB级别的**海量数据集**。

## 2、MapReduce的思想

MapReduce擅长处理大数据，MapReduce的思想是**“分而治之”**。

　　（1）Mapper负责“分”，即把复杂的任务分解为若干个“简单的任务”来处理。“简单的任务”意味着：一是数据或计算的规模相对原任务要大大缩小；二是就近计算原则，即任务会分配到存放着所需数据的节点上进行计算；三是这些小任务可以并行计算，彼此间几乎没有依赖关系。

　　（2）Reducer负责对map阶段的结果进行汇总。至于需要多少个Reducer，用户可以根据具体问题，通过在mapred-site.xml配置文件里设置参数mapred.reduce.tasks的值，缺省值为1。

## 3、MapReduce的框架

​		MapReduce架构成员通常来说，MapReduce计算引擎的核心架构，包括有**Client、Job Tracker、TaskTracker以及Task。**

​		**ClientClient**的含义是指用户使用MapReduce程序通过Client来提交任务到Job Tracker上，同时用户也可以使用Client来查看一些作业的运行状态。

​		**Job TrackerJob Tracker**负责的是资源监控和作业调度。JobTracker会监控着TaskTracker和作业的健康状况，会把失败的任务转移到其他节点上，同时也监控着任务的执行进度、资源使用量等情况，会把这些消息通知任务调度器，而调度器会在资源空闲的时候选择合适的任务来使用这些资源。

​		**TaskTrackerTaskTracker**会周期性地通过Hearbeat来向Job Tracker汇报自己的资源使用情况和任务的运行进度。会接受来自于JobTaskcker的指令来执行操作（例如启动新任务、杀死任务之类的）。在TaskTracker中通过的是slot来进行等量划分一个节点上资源量，只用Task获得slot的时候才有机会去运行。TaskTask分为Map Task和Reduce Task，在MapReduce中的split就是一个Map Task，split的大小可以设置的，由mapred.max.spilt.size参数来设置，默认是Hadoop中的block的大小。

## 4、MapReduce工作流程

MapReduce的工作流程大致可以分为5步，具体如下：

**1、分片、格式化数据源**

​		输入Map阶段的数据源，必须经过分片和格式化操作。

​		分片操作：指的是将源文件划分为大小相等的小数据块（Hadoop2.x中默认128M），也就是分片(split)，Hadoop会为每一个分片构建一个Map任务，并由该任务运行自定义的map()函数，从而处理分片里的每一条记录。

​		格式化操作：将划分好的分片（split）格式化为键值对<key，value>形式的数据，其中，key代表偏移量，value代表每一行内容。

**2、执行MapTask**

​		每个Map任务都有一个内存缓冲区（缓冲区大小100M），输入的分片（split）数据经过Map任务处理后的中间结果，会写入内存缓冲区中。如果写入的数据达到内存缓冲的阀值（80M），会启动一个线程将内存中的溢出数据写入磁盘，同时不影响map中间结果继续写入缓冲区。

​		在溢写过程中，MapReduce框架会对Key进行排序，如果中间结果比较大，会形成多个溢写文件，最后的缓冲区数据也会全部溢写入磁盘形成一个溢写文件，如果是多个溢写文件，则最后合并所有的溢写文件为一个文件。

**3、执行Shuffle过程**

​		MapReduce工作过程中，map阶段处理的数据如何传递给Reduce阶段，这是MapReduce框架中关键的一个过程，这个过程叫做Shuffle。

​		Shuffle会将MapTask输出的处理结果数据，分发给ReduceTask，并在分发的过程中，对数据按key进行分区和排序。

**4、执行ReduceTask**

​		输入ReduceTask的数据流是<key，{value list}>形式，用户可以自定义reduce()方法进行逻辑处理，最终以<key，value>的形式输出。

**5、写入文件**

​		MapReduce框架会自动把ReduceTask生成的<key,value>传入OutputFormat的write方法，实现文件的写入操作。

## 5、MapReduce实例进程

​		MapReduce是Hadoop核心三剑客之一，设计思想来源于谷歌三篇论文之一的《分布式计算模型》。作为一个分布式运算程序编程框架，需要用户实现业务逻辑代码并和它自带的默认组件整合成完整的分布式运算程序，并发运行在Hadoop集群上。一个完整的MapReduce程序在分布式运行时有三类实例进程：

**1. MRAppMaster****：负责整个程序过程调度及状态协调**

**2. MapTask****：负责map阶段整个数据处理流程**

**3. ReduceTask****：负责reduce阶段整个数据处理流程**
